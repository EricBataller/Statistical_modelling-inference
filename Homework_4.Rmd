---
title: "Statistical Modeling and Inference - Homework 4"
author: "Eric Bataller"
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

```{r}
knitr::opts_chunk$set(message= FALSE, warning = FALSE)
```

In this question we are going to use topic modeling to understand how parliamentary speech varies by the gender of the MP. We will be working with a corpus of speeches made by legislators in the UK House of Commons in the 2014 calendar year. Specificaly, we'll make use of Structural topic modeling.

Import libraries:
```{r}
library(readr)
library(quanteda) 
library(quanteda.textplots) # complementary to quanteda, for visualization
library(topicmodels)
library(LDAvis) 
library(stm)
library(knitr)
library(lda)
library(servr)
library(dplyr)
set.seed(5528) # set seed for reproductibility
PATH= 'C:/Users/ericb/Desktop/Data Science/BSE_Data_Science_master/Statistical Modeling and Inference/Part 2 - Clustering, PCA, LDA/Seminar5'
```

# Load the data from the representatives:

```{r}
load(file.path(PATH,"data/hoc_speeches.Rdata"))
```

# Data exploration

```{r}
#Remove repeated ones
speechesDF <- distinct(speeches, speech, .keep_all = TRUE)

sapply(speechesDF, class)
summary(speechesDF)
prop.table(table(speechesDF$party, speechesDF$gender),1)
```

```{r}
speechesDF$ntoken <- ntoken(speechesDF$speech)
hist(speechesDF$ntoken, main = "Histogram of speech length", xlim = c(0, 4000), breaks = 300)

```

# Use the functions in the `quanteda` package to turn this data into a `corpus` object.

We create the corpus and retain only documents with a length between 50 and 800.

```{r}
#Create corpus:
speeches_Corpus <- corpus(speechesDF$speech, docvars = speechesDF)

#Filtering doc lenght:
ntokens_corpus <- ntoken(speeches_Corpus)
docs_length50_800 <- names(ntokens_corpus[(ntokens_corpus>=50) & (ntokens_corpus<=800)])
speeches_Corpus <- speeches_Corpus[names(speeches_Corpus) %in% docs_length50_800]

#Print summary:
summary(speeches_Corpus, n = 4) #summary() from quanteda package. We only print [,0:4] to avoid printing the speech column
head(speeches_Corpus)
```
List of common words we will remove from our texts. 

```{r}
custom_list_stopwords <- c(stopwords("en"), 'also', 'may','can','hon','govern','will', 'welcome','go','make','s')
```

# Turn this corpus into a tokens object and then into a document-feature matrix.

```{r}
speechDFM_filtered <- tokens(speeches_Corpus, remove_punct = TRUE, 
                                    remove_symbols = TRUE, remove_numbers = TRUE) %>% 
                      tokens_remove(custom_list_stopwords) %>% #Remove words contained in custom_list
                      tokens_wordstem() %>%
                      tokens_remove(custom_list_stopwords) %>% #Remove potential stemmed words in custom_list
                      tokens_ngrams(n = c(1, 2)) %>% #include all the individual words and the groups of 2 words
                      dfm() %>% 
                      dfm_tolower() %>%
                      dfm_trim(min_termfreq = 5, min_docfreq = 0.0025, docfreq_type = "prop") #Remove unfrequent words
speechDFM_filtered
```
Plot the words by overall frequency:

```{r}
textplot_wordcloud(speechDFM_filtered, random_order = FALSE, rotation = 0.25, 
    color = RColorBrewer::brewer.pal(8, "Dark2"),max_words =150,max_size = 3)
```

# Run a structural topic model for this corpus, using the gender variable in the topic prevalence argument. Use the stm function to do this.

```{r ,results= "hide", message= FALSE, warning=FALSE, error=FALSE}
K <- 20
fitted_stm <- stm(documents = speechDFM_filtered, 
              data = docvars(speechDFM_filtered),
              prevalence = ~gender,
              K = K, seed = 123, verbose = TRUE)

```

# Specify and estimate the stm model:

Estimated topic model:

```{r}
plot(fitted_stm)
```

Top words from each topic:

```{r}
topic_labels <- labelTopics(fitted_stm)
top_words <- apply(topic_labels$prob, 1, function(x) paste(x, collapse=", "))
print(top_words)
```

Top three documents associated with each topic:

```{r}
top_docs <- apply(fitted_stm$theta, 2, function(x) order(x, decreasing = T)[1:3])
top_docs
```
Report the top speeches for one selected topic:

```{r}
top_busi_docs <- top_docs[,grep("busi",top_words)]
docvars(speechDFM_filtered)[top_busi_docs,"speech"]
```

We can see that the 3 speeches are related to business and economy in general, which seems to be sort of the underlying theme of topic number 8.

# Use the estimateEffect and plot.estimateEffect functions in the stm package to estimate the effect of MP gender on topic usage.

```{r}
est_gender_effect <- estimateEffect(~gender, fitted_stm, metadata = docvars(speechDFM_filtered))
plot.estimateEffect(est_gender_effect, "gender", method = "difference", 
                    cov.value1 = "female", cov.value2 = "male", 
                    labeltype = "custom", n = 2, verbose.labels = F, custom.labels = sprintf("Topic %s", 1:20),
                    model = fitted_stm)

```


On which topics are women, on average, more active?

We can see the differences on activity of each topics. Specifically, some of the ones that stand out by the greater activity on female MP are:

Topic 20: "servic, care, health, nhs, patient, hospit, trust"...
Topic 13: "countri, european, union, right, eu, british, intern"...
Topic 8: "busi, economi, econom, industri, bank, invest, small"...

Nonetheless, none of the CI reports a "greater than 0 difference between the probability of each topic". Thus, the differences observed are not so significant. 









